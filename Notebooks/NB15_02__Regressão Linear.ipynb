{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "NB15_02__Regressão Linear.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KMInada/DSWP/blob/Exercicios/Notebooks/NB15_02__Regress%C3%A3o%20Linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwQDhId7N6_r"
      },
      "source": [
        "<center><h1><b><i>MACHINE LEARNING WITH PYTHON</i></b></h1></center>\n",
        "<center><h1><b><i>APRENDIZAGEM SUPERVISIONADA</i></b></h1></center>\n",
        "<center><h1><b><i>MODELOS DE REGRESSÃO (LINEAR E LOGÍSTICA)</i></b></h1></center>\n",
        "\n",
        "Fonte: https://realpython.com/linear-regression-in-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN-dQFJcM1UV"
      },
      "source": [
        "Passos para implementação da Regressão Linear:\n",
        "\n",
        "* (1) Importar as libraries necessárias;\n",
        "* (2) Carregar os dados;\n",
        "* (3) Aplicar as transformações necessárias: outliers, NaN's, normalização (MinMaxScaler, RobustScaler, StandarScaler, Log, Box-Cox e etc);\n",
        "* (4) Construir e treinar o modelo preditivo (neste caso, modelo de regressão);\n",
        "* (5) Validar/verificar as métricas para avaliação do(s) modelo(s);\n",
        "* (6) Predições."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TldGZxAFV5E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QRbxlqaq7pr"
      },
      "source": [
        "# Melhorias da sessão:\n",
        "* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4sAIblOgFyL"
      },
      "source": [
        "# Modelos de Regressão com Regularization para Classificação e Regressão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Y7cuJNgFyU"
      },
      "source": [
        "## Regressão Linear Simples (usando OLS - Ordinary Least Squares)\n",
        "\n",
        "* Features $X_{np}$: é uma matriz de dimensão nxp;\n",
        "* Variável target/dependente representada por y;\n",
        "* Relação entre X e y é representado pela equação abaixo, onde $w_{i}$ representa os pesos de cada coeficiente e $w_{0}$ representa o intercepto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJ580y9gFyU"
      },
      "source": [
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/lm1.PNG?raw=true\" width=\"300\">\n",
        "\n",
        "![X_y](https://github.com/MathMachado/Materials/blob/master/Architecture.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rhbVGJ0gFyY"
      },
      "source": [
        "* Soma de Quadrados dos Resíduos (RSS) - Soma de Quadrados das diferenças entre os valores observados e preditos.\n",
        "\n",
        "<img src=\"https://github.com/awantik/machine-learning-slides/blob/master/lm2.PNG?raw=true\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8gA0YkbgFyp"
      },
      "source": [
        "## Principais parâmetros do algoritmo:\n",
        "* fit_intercept - Indica se o intercepto $w_{0}$ deve ou não ser ajustado. Se os dados estão normalizados, então não faz sentido ajustar o intercepto $w_{0}$.\n",
        "\n",
        "* normalize - $X$ será automaticamente normalizada (subtrai a média e divide pelo desvio-padrão);\n",
        "\n",
        "## Atributos do modelo de Machine Learning para Regressão\n",
        "* coef - peso/fator de cada variável independente do modelo de ML;\n",
        "\n",
        "* intercepto $w_{0}$ - intercepto ou viés de $y$;\n",
        "\n",
        "## Funções para ajuste do ML:\n",
        "* fit - treina o modelo com as matrizes $X$ e $y$;\n",
        "* predict - Uma vez que o modelo foi treinado, para um dado $X$, use $y$ para calcular os valores preditos de $y$ (y_pred).\n",
        "\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-JG8El1gFy7"
      },
      "source": [
        "# Limitações do OLS:\n",
        "* Impactado/sensível à Outliers;\n",
        "* Multicolinearidade; \n",
        "* Heterocedasticidade - apresenta-se como uma forte dispersão dos dados em torno de uma reta;\n",
        "\n",
        "* <a href=\"http://www.clockbackward.com/2009/06/18/ordinary-least-squares-linear-regression-flaws-problems-and-pitfalls/\">References</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xylMYR8COyrw"
      },
      "source": [
        "### Importar as libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BGgrILlPK6Z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "263GgbwhO2kQ"
      },
      "source": [
        "### Carregar os dados\n",
        "* Vamos carregar o dataset [Boston House Pricing](https://archive.ics.uci.edu/ml/datasets/housing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2WoVKwkPYEd"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "#url = 'https://raw.githubusercontent.com/MathMachado/DSWP/master/Dataframes/housing.csv'\n",
        "\n",
        "# Variáveis preditoras\n",
        "df_boston = pd.DataFrame(load_boston().data, columns = boston.feature_names)\n",
        "df_boston['preco'] = load_boston().target\n",
        "df_boston.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__FoIud_e9b8"
      },
      "source": [
        "df_boston.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H71da4bIO4kI"
      },
      "source": [
        "### Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-6YOdsTfciO"
      },
      "source": [
        "#### Normalização/padronização dos nomes das colunas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8OJEapufhq4"
      },
      "source": [
        "df_boston.columns = [col.lower() for col in df_boston.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRinX-5ofol_"
      },
      "source": [
        "df_boston.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMDh5jyqekmr"
      },
      "source": [
        "#### Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJIG0jJQf6em"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgYPzlvfemFc"
      },
      "source": [
        "#### Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAjw7UhJen0D"
      },
      "source": [
        "# Missing values por colunas/variáveis\n",
        "df_boston.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yp8g7hxfQli"
      },
      "source": [
        "# Missing Values por linhas\n",
        "df_boston[df_boston.isnull().any(axis = 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmkTFLrf9MT"
      },
      "source": [
        "#### Estatísticas Descritivas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nprn3p_Wf_bn"
      },
      "source": [
        "df_boston.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JimyY3SgECE"
      },
      "source": [
        "#### Análise de Correlação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jScHq7eTgIpm"
      },
      "source": [
        "correlacoes = df_boston.corr()\n",
        "correlacoes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxQp7xqdgTJP"
      },
      "source": [
        "##### Gráfico das correlações entre as features/variáveis/colunas\n",
        "Source: https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOiH2X-WgqmN"
      },
      "source": [
        "import seaborn as sns\n",
        "from string import ascii_letters\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_theme(style = \"white\")\n",
        "\n",
        "d = df_boston\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = d.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nogPhyfVO70G"
      },
      "source": [
        "### Construir e treinar o(s) modelo(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BhLZJhibVNG"
      },
      "source": [
        "X_boston = df_boston.drop(columns = ['preco'], axis = 1)\n",
        "y_boston = df_boston['preco']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50_6tv5h1kY"
      },
      "source": [
        "# Definindo os dataframes de treinamento e teste:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_boston, y_boston, test_size = 0.2, random_state = 20111974)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvevXulFiJj1"
      },
      "source": [
        "#### Treinamento do modelo de Regressão Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVwF3vp8iNff"
      },
      "source": [
        "# Importa a library LinearRegression --> Para treinamento da Regressão Linear\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Library para statmodels\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibX6bCbViW-v"
      },
      "source": [
        "# Instancia o objeto\n",
        "regressao_linear = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-5wRGUribY0"
      },
      "source": [
        "# Treina o modelo usando as amostras/dataset de treinamento: X_treinamento e y_treinamento \n",
        "regressao_linear.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jri-jA1VjmUl"
      },
      "source": [
        "# Valor do intercepto\n",
        "regressao_linear.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOjadxdxjqtT"
      },
      "source": [
        "# Coeficientes do modelo de Regressão Linear\n",
        "coeficientes_regressao_linear = pd.DataFrame([X_treinamento.columns, regressao_linear.coef_]).T\n",
        "coeficientes_regressao_linear = coeficientes_regressao_linear.rename(columns={0: 'Feature/variável/coluna', 1: 'Coeficientes'})\n",
        "coeficientes_regressao_linear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwnkhPwDjkhS"
      },
      "source": [
        "#### Usando statmodels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltbekHd_k3PH"
      },
      "source": [
        "X2_treinamento = sm.add_constant(X_treinamento)\n",
        "lm_sm = sm.OLS(y_treinamento, X2_treinamento).fit()\n",
        "print(lm_sm.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UafIUrpZB0YP"
      },
      "source": [
        "### Conclusão\n",
        "* Quais variáveis/colunas/atributos ficam no modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXeiFtnJO_1u"
      },
      "source": [
        "### Validação do(s) modelo(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlGVFA6uPDvr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE3aKJ6mPDyJ"
      },
      "source": [
        "### Predições"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YQF4NIlGSLH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQfpoo1igFy8"
      },
      "source": [
        "# Regularized Regression Methods \n",
        "## Ridge Regression - Penalized Regression\n",
        "> Reduz a complexidade do modelo através do uso de todas as variáveis de $X$, mas penalizando (valor de $\\alpha$) os coeficientes $w_{i}$ quando estiverem muito longe de zero, forçando-os a serem pequenos de maneira contínua. Dessa forma, diminuímos a complexidade do modelo enquanto mantemos todas as variáveis no modelo.\n",
        "* Menor impacto dos outliers.\n",
        "\n",
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp4VIJWxgFy8"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge(alpha = .1)\n",
        "lr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmRMoOwV6FMt"
      },
      "source": [
        "ridge = Ridge(alpha = .1)\n",
        "ridge.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPnekyUbK6Xg"
      },
      "source": [
        "#### Peso/contribuição das variáveis para a regressão usando RIDGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMCb0CFjK973"
      },
      "source": [
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqksuIjXypRJ"
      },
      "source": [
        "# treinando a regressão Ridge\n",
        "ridge.fit(X_treinamento, y_treinamento)\n",
        "\n",
        "# treinando a regressão linear simples (OLS)\n",
        "lr.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r28PBsWLtjA"
      },
      "source": [
        "ridge.alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRMK_QTmNgc1"
      },
      "source": [
        "# maior alpha --> mais restrição aos coeficientes; \n",
        "# Menor alpha --> mais generalização, e Ridge se assemelha da OLS\n",
        "rr = Ridge(alpha = 0.01)\n",
        "rr.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRuWmBE7Ngc7"
      },
      "source": [
        "# MSE\n",
        "rr_model=(mean_squared_error(y_true = y_treinamento, y_pred = rr.predict(X_treinamento)))\n",
        "print(rr_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEaj4QRrNgdA"
      },
      "source": [
        "rr100 = Ridge(alpha=100)\n",
        "rr100.fit(X_treinamento, y_treinamento)\n",
        "train_score=lr.score(X_treinamento, y_treinamento)\n",
        "test_score=lr.score(X_teste, y_teste)\n",
        "Ridge_treinamento_score = rr.score(X_treinamento,y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhcfoTEENgdE"
      },
      "source": [
        "# MSE\n",
        "rr100_model = (mean_squared_error(y_true = y_treinamento, y_pred = rr100.predict(X_treinamento)))\n",
        "print(rr100_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEF_3GgUgF0Q"
      },
      "source": [
        "# Lasso\n",
        "* Reduz overfitting;\n",
        "* Se encarrega do Feature Selection, pois descarta variáveis altamente correlacionadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YiKb9reQdI4"
      },
      "source": [
        "* Usado no processo de Regularization - processo de penalizar as variáveis para manter somente os atributos mais importantes. Pense na utilidade disso diante de um dataframe com muitas variáveis;\n",
        "* A regressão Lasso vem com um parâmetro ($\\alpha$), e quanto maior o alfa, a maioria dos coeficientes de recurso é zero. Ou seja, quando $\\alpha = 0$, a regressão Lasso produz os mesmos coeficientes que uma regressão linear. Quando alfa é muito grande, todos os coeficientes são zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME6v6LFlgF0Q"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha = .1)\n",
        "lasso.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6DSEHc1gF0V"
      },
      "source": [
        "lasso.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP1fX1Bi6VdX"
      },
      "source": [
        "Coeficientes zero podem ser excluídos da Análise/modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P7hYoo4gF0Z"
      },
      "source": [
        "# Elastic Net  \n",
        "* Combina o poder de Ridge e LASSO;\n",
        "* Remove variáveis de pouco poder preditivo (LASSO) ou as penaliza (Ridge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChNUYs7gF0b"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instancia o objeto\n",
        "en = ElasticNet(alpha = .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mbIaAUAF4N6"
      },
      "source": [
        "en.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaUkZw8ngF0h"
      },
      "source": [
        "en.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl-Qh9caDyCp"
      },
      "source": [
        "# Instancia o objeto:\n",
        "en = ElasticNet(normalize = True)\n",
        "\n",
        "# Otimização dos hiperparâmetros:\n",
        "d_hiperparametros = {'alpha': np.logspace(-5, 2, 8), \n",
        "                     'l1_ratio': [.2, .4, .6, .8]}\n",
        "\n",
        "search = GridSearchCV(estimator = en, \n",
        "                      param_grid = d_hiperparametros, \n",
        "                      scoring = 'neg_mean_squared_error', \n",
        "                      n_jobs = 1,\n",
        "                      refit = True, \n",
        "                      cv = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3_XCQCPGlr3"
      },
      "source": [
        "search.fit(X_treinamento, y_treinamento)\n",
        "search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq0_ugQfGrdb"
      },
      "source": [
        "en2 = ElasticNet(normalize = True, alpha = 0.001, l1_ratio = 0.6)\n",
        "en2.fit(X_treinamento, y_treinamento)\n",
        "\n",
        "# Métrica\n",
        "ml2 = (mean_squared_error(y_true = y_teste, y_pred = en2.predict(X_teste)))\n",
        "print(ml2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoxf9KKYOjEd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUUrajAxOkHg"
      },
      "source": [
        "# Regularized Regression Methods \n",
        "## Ridge Regression - Penalized Regression\n",
        "> Reduz a complexidade do modelo através do uso de todas as variáveis de $X$, mas penalizando os coeficientes $w_{i}$ quando estiverem muito longe de zero, forçando-os a serem pequenos de maneira contínua. Dessa forma, diminuímos a complexidade do modelo enquanto mantemos todas as variáveis no modelo.\n",
        "* Menor impacto dos outliers.\n",
        "\n",
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVBd5g8NOkHh"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge(alpha = .1)\n",
        "lr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o00xH2MvxvgP"
      },
      "source": [
        "# Matriz de covariáveis do modelo:\n",
        "X_new = [[0, 0], [0, 0], [1, 1]]\n",
        "y_new = [0, .1, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9U7c03NzW_c"
      },
      "source": [
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiVEAPpUzXyN"
      },
      "source": [
        "y_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mWj2GbPOkHx"
      },
      "source": [
        "ridge = Ridge(alpha = .1)\n",
        "ridge.fit(X_new, y_new)\n",
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kD7Bsq_OkH1"
      },
      "source": [
        "# treinando a regressão Ridge\n",
        "ridge.fit(X, y)\n",
        "\n",
        "# treinando a regressão linear simples (OLS)\n",
        "lr.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUEyK4lygFy_"
      },
      "source": [
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRLUwIugFzC"
      },
      "source": [
        "lr.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URcHb6uggFzF"
      },
      "source": [
        "# Adicionar alguns outliers aos dados\n",
        "outliers = y[950:] - 600\n",
        "outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqA2dFQWgFzH"
      },
      "source": [
        "import numpy as np\n",
        "y_outlier = np.append(y[:950], outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YRDzmZkgFzL"
      },
      "source": [
        "plt.scatter(X, y_outlier, s=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wFZ_AX1gFzU"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X, y_outlier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NYzB9nEgFze"
      },
      "source": [
        "y_pred_outliers= lr.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7aaUXzDgFzh"
      },
      "source": [
        "plt.scatter(X, y_outlier,s=5,label='actual')\n",
        "plt.scatter(X, y_pred_outliers,s=5,label='prediction with outliers')\n",
        "plt.scatter(X, y_pred,s=5,c='k', label='prediction sem outlier')\n",
        "plt.legend()\n",
        "plt.title('Linear Regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LON9hAomgFzl"
      },
      "source": [
        "lr.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Yu7pAigFzt"
      },
      "source": [
        "ridge = Ridge(alpha = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB9fKEImgFzw"
      },
      "source": [
        "ridge.fit(X, y_outlier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4DxOv8EgFzz"
      },
      "source": [
        "y_pred_ridge = ridge.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVWQuFVegFz2"
      },
      "source": [
        "plt.scatter(X, y_outlier, s = 5,label = 'actual')\n",
        "plt.scatter(X, y_pred_outliers, s = 5, c = 'r' ,label = 'LinearRegression with outliers')\n",
        "plt.scatter(X, y_pred_ridge, s = 5, c = 'k', label = 'RidgeRegression with outlier')\n",
        "plt.legend()\n",
        "plt.title('Linear Regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seq5MCvDgFz5"
      },
      "source": [
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d0DL3YYgFz-"
      },
      "source": [
        "## Efeito de $\\alpha$ na Regressão Ridge\n",
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCA4BvRkgFz_"
      },
      "source": [
        "X, y, w = make_regression(n_samples = 10, \n",
        "                          n_features = 10, \n",
        "                          coef = True, \n",
        "                          random_state = 1, \n",
        "                          bias = 3.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l2zCIX6gF0D"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSXLQl5COkI8"
      },
      "source": [
        "# Lasso\n",
        "* Reduz overfitting;\n",
        "* Se encarrega do Feature Selection, pois descarta variáveis altamente correlacionadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5JZTnkTOkI9"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha = .1)\n",
        "lasso.fit([[0, 0], [0, 0], [1, 1]],  [0, .1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEUxSlThOkJD"
      },
      "source": [
        "lasso.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90pfP9-3OkJG"
      },
      "source": [
        "Observe acima que o segundo coeficiente foi estimado como 0 e, desta forma, podemos excluí-lo do ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILCXvYKDOkJH"
      },
      "source": [
        "# Elastic Net  \n",
        "* Combina o poder de Ridge e LASSO;\n",
        "* Remove variáveis de pouco poder preditivo (LASSO) ou as penaliza (Ridge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaQPDCR2OkJI"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Instancia o objeto\n",
        "en = ElasticNet(alpha = .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVp16Eu_OkJL"
      },
      "source": [
        "en.fit([[0, 0], [0, 0], [1, 1]],  [0, .1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwj018U8OkJO"
      },
      "source": [
        "en.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTvoKmbY_uXM"
      },
      "source": [
        "# Exemplo completo: Ridge\n",
        "* Adaptado de [Ridge and Lasso Regression: A Complete Guide with Python Scikit-Learn](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If7A_ceC_wW4"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93n7uz0X_367"
      },
      "source": [
        "boston = load_boston()\n",
        "df_Boston = pd.DataFrame(boston.data, columns = boston.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqRuXuzB_8Ge"
      },
      "source": [
        "X_boston = boston.data\n",
        "y_boston = boston.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NztUeubIACuA"
      },
      "source": [
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_boston, y_boston, test_size = 0.2, random_state = 20111974)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNwBSc1FAEoB"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9BrlLSIAHS3"
      },
      "source": [
        "# maior alpha --> mais restrição aos coeficientes; \n",
        "# Menor alpha --> mais generalização, e Ridge se assemelha da OLS\n",
        "rr = Ridge(alpha = 0.01)\n",
        "rr.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dchr1UwjEn-A"
      },
      "source": [
        "# MSE\n",
        "rr_model=(mean_squared_error(y_true = y_treinamento, y_pred = rr.predict(X_treinamento)))\n",
        "print(rr_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnic6PY-CV-P"
      },
      "source": [
        "rr100 = Ridge(alpha=100)\n",
        "rr100.fit(X_treinamento, y_treinamento)\n",
        "train_score=lr.score(X_treinamento, y_treinamento)\n",
        "test_score=lr.score(X_teste, y_teste)\n",
        "Ridge_treinamento_score = rr.score(X_treinamento,y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIe76z26EdG5"
      },
      "source": [
        "# MSE\n",
        "rr100_model = (mean_squared_error(y_true = y_treinamento, y_pred = rr100.predict(X_treinamento)))\n",
        "print(rr100_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAuvhdNdAJ7C"
      },
      "source": [
        "Ridge_teste_score = rr.score(X_teste, y_teste)\n",
        "Ridge_treinamento_score100 = rr100.score(X_treinamento, y_treinamento)\n",
        "Ridge_teste_score100 = rr100.score(X_teste, y_teste)\n",
        "print(\"linear regression train score:\", train_score)\n",
        "print(\"linear regression test score:\", test_score)\n",
        "print(\"ridge regression train score low alpha:\", Ridge_treinamento_score)\n",
        "print(\"ridge regression test score low alpha:\", Ridge_teste_score)\n",
        "print(\"ridge regression train score high alpha:\", Ridge_treinamento_score100)\n",
        "print(\"ridge regression test score high alpha:\", Ridge_teste_score100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0OaweJrCchd"
      },
      "source": [
        "plt.plot(rr.coef_, \n",
        "         alpha = 0.7, \n",
        "         linestyle = 'none', \n",
        "         marker = '*', \n",
        "         markersize = 5, \n",
        "         color = 'red', \n",
        "         label = r'Ridge; \n",
        "         $\\alpha = 0.01$', \n",
        "         zorder = 7) # zorder for ordering the markers\n",
        "\n",
        "plt.plot(rr100.coef_,alpha = 0.5, \n",
        "         linestyle = 'none', \n",
        "         marker = 'd', \n",
        "         markersize = 6, \n",
        "         color = 'blue', \n",
        "         label = r'Ridge; \n",
        "         $\\alpha = 100$') # alpha here is for transparency\n",
        "\n",
        "plt.plot(lr.coef_, \n",
        "         alpha = 0.4, \n",
        "         linestyle = 'none', \n",
        "         marker = 'o', \n",
        "         markersize = 7, \n",
        "         color = 'green', \n",
        "         label = 'Linear Regression')\n",
        "\n",
        "plt.xlabel('Coefficient Index', fontsize = 16)\n",
        "plt.ylabel('Coefficient Magnitude',fontsize = 16)\n",
        "plt.legend(fontsize = 13, loc = 4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEtGRcl-EHaF"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rr_model=(mean_squared_error(y_true= y, y_pred=regression.predict(X)))\n",
        "print(first_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dwlPByHDipf"
      },
      "source": [
        "# Exemplo completo - Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhbIfGnfOkKF"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instancia o objeto:\n",
        "en = ElasticNet(normalize = True)\n",
        "\n",
        "# Otimização dos hiperparâmetros:\n",
        "d_hiperparametros = {'alpha': np.logspace(-5, 2, 8), \n",
        "                     'l1_ratio': [.2, .4, .6, .8]}\n",
        "\n",
        "search = GridSearchCV(estimator = en, \n",
        "                      param_grid = d_hiperparametros, \n",
        "                      scoring = 'neg_mean_squared_error', \n",
        "                      n_jobs = 1,\n",
        "                      refit = True, \n",
        "                      cv = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDPkRazPOkKJ"
      },
      "source": [
        "search.fit(X, y)\n",
        "search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_K-f8KCOkKM"
      },
      "source": [
        "en2 = ElasticNet(normalize = True, alpha = 0.001, l1_ratio = 0.6)\n",
        "en2.fit(X, y)\n",
        "\n",
        "ml2 = (mean_squared_error(y_true = y, y_pred = en2.predict(X)))\n",
        "print(ml2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5o7FiRm9_vb"
      },
      "source": [
        "# Exercício 1 - Regressão Linear - Mall_Customers.csv\n",
        "> A variável-target deste dataframe é 'Annual Income'. Desenvolva um modelo de regressão utilizando OLS, Ridge e LASSO e compare os resultados.\n",
        "\n",
        "* Experimente:\n",
        "    * Lasso(alpha = 0.01, max_iter = 10e5);\n",
        "    * Lasso(alpha = 0.0001, max_iter = 10e5);\n",
        "    * Ridge(alpha = 0.01);\n",
        "    * Ridge(alpha = 100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJRWBzSQCcss"
      },
      "source": [
        "# Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucn0pQThO1eN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwuMfMD1gFyd"
      },
      "source": [
        "# Exemplo para regressão LOGÍSTICA!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efF3st3sHxPG"
      },
      "source": [
        "# Carrega as bibliotecas\n",
        "import numpy as np\n",
        "np.set_printoptions(formatter = {'float': lambda x: \"{0:0.2f}\".format(x)})\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk9F6JO0IELv"
      },
      "source": [
        "# Carregar/ler o banco de dados - Dataframe Diabetes\n",
        "from sklearn import datasets\n",
        "#Diabetes = datasets.load_diabetes()\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/MathMachado/DSWP/master/Dataframes/diabetes.csv'\n",
        "diabetes = pd.read_csv(url)\n",
        "diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjRmpaPIDknb"
      },
      "source": [
        "# Definir as matrizes X e y\n",
        "X_diabetes = diabetes.copy()\n",
        "X_diabetes.drop(columns = ['Outcome'], axis = 1, inplace = True)\n",
        "y_diabetes = diabetes['Outcome']\n",
        "\n",
        "X_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLrx69TH-Mad"
      },
      "source": [
        "X_diabetes.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdFBioP6-Ply"
      },
      "source": [
        "y_diabetes.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhLySN65IaDF"
      },
      "source": [
        "# Definir as matrizes de treinamento e validação\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_diabetes, y_diabetes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5R8HlnuIGpL"
      },
      "source": [
        "# Carregar a library LinearRegression()\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instanciar o objeto\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Usando statmodels:\n",
        "x = sm.add_constant(X_treinamento)\n",
        "lr_sm = sm.Logit(y_treinamento, X_treinamento) # Atenção: aqui é o contrário: [y, x]\n",
        "\n",
        "# Treinar o modelo\n",
        "lr.fit(X_treinamento, y_treinamento)\n",
        "resultado_sm = lr_sm.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlbCaPp1ETNa"
      },
      "source": [
        "resultado_sm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7hWIjr0J8fd"
      },
      "source": [
        "# Coeficientes do modelo\n",
        "lr.coef_   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DVjyWUUKH4t"
      },
      "source": [
        "# Intercepto do modelo\n",
        "lr.intercept_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FJaSnJLKICU"
      },
      "source": [
        "# EQM - Erro Quadrático Médio\n",
        "np.mean((lr.predict(X_teste) - y_teste) ** 2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bVEUSTUPzOj"
      },
      "source": [
        "### Calcular y_pred - os valores preditos de y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjGrNhTNLcr-"
      },
      "source": [
        "y_pred = lr.predict(X_treinamento)\n",
        "\n",
        "# Predit com statmodels\n",
        "resultado_sm.predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FolXBGbFFUnE"
      },
      "source": [
        "np.array(diabetes['Outcome'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUxasncIFaw4"
      },
      "source": [
        "resultado_sm.pred_table()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_liLYinwFgch"
      },
      "source": [
        "confusion_matrix = pd.DataFrame(resultado_sm.pred_table())\n",
        "confusion_matrix.columns = ['Predicted No Diabetes', 'Predicted Diabetes']\n",
        "confusion_matrix = confusion_matrix.rename(index = {0 : 'Actual No Diabetes', 1 : 'Actual Diabetes'})\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceH3MODWFm7S"
      },
      "source": [
        "cm = np.array(confusion_matrix)\n",
        "training_accuracy = (cm[0,0] + cm[1,1])/ cm.sum()\n",
        "training_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfRda6kWFzHZ"
      },
      "source": [
        "### Testando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0n-pdnkF3MC"
      },
      "source": [
        "test_cleaned = test_data['Outcome']\n",
        "test_data = test_data.drop(['Outcome'], axis = 1)\n",
        "test_data = sm.add_constant(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5hTgpelF5Pu"
      },
      "source": [
        "def confusion_matrix(data, actual_values, model):\n",
        "    predicted_values = model.predict(data)\n",
        "    bins = np.array ([0, 0.5, 1])\n",
        "    cm = np.histogram2d(actual_values, predicted_values, bins = bins)[0]\n",
        "    accuracy = (cm[0,0] + cm[1,1])/cm.sum()\n",
        "    return cm, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PBK6M8yF7JE"
      },
      "source": [
        "conf_matrix = confusion_matrix(test_data, test_cleaned, result)\n",
        "conf_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQz6ys7EF854"
      },
      "source": [
        "confusion_matrix = pd.DataFrame(conf_matrix[0])\n",
        "confusion_matrix.columns = ['Predicted No Diabetes', 'Predicted Diabetes']\n",
        "confusion_matrix = confusion_matrix.rename(index = {0 : 'Actual No Diabetes', 1 : 'Actual Diabetes'})\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MeuBR4QO1x3"
      },
      "source": [
        "# Regularized Regression Methods \n",
        "## Ridge Regression - Penalized Regression\n",
        "> Reduz a complexidade do modelo através do uso de todas as variáveis de $X$, mas penalizando os coeficientes $w_{i}$ quando estiverem muito longe de zero, forçando-os a serem pequenos de maneira contínua. Dessa forma, diminuímos a complexidade do modelo enquanto mantemos todas as variáveis no modelo.\n",
        "* Menor impacto dos outliers.\n",
        "\n",
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1gLVnjXO1x6"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge(alpha = .1)\n",
        "lr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0neeicWaO1yA"
      },
      "source": [
        "# Matriz de covariáveis do modelo:\n",
        "X_new = [[0, 0], [0, 0], [1, 1]]\n",
        "y_new = [0, .1, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDB5Bd0O1yE"
      },
      "source": [
        "X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UldOGKA6O1yJ"
      },
      "source": [
        "y_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRzwxGWpO1yO"
      },
      "source": [
        "ridge = Ridge(alpha = .1)\n",
        "ridge.fit(X_new, y_new)\n",
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXas7SfCO1yR"
      },
      "source": [
        "# treinando a regressão Ridge\n",
        "ridge.fit(X, y)\n",
        "\n",
        "# treinando a regressão linear simples (OLS)\n",
        "lr.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvQY7qzBO1yV"
      },
      "source": [
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg1Z4h5tO1yY"
      },
      "source": [
        "lr.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puj1I_8CO1yd"
      },
      "source": [
        "# Adicionar alguns outliers aos dados\n",
        "outliers = y[950:] - 600\n",
        "outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw4Q3q6lO1yg"
      },
      "source": [
        "import numpy as np\n",
        "y_outlier = np.append(y[:950], outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq7ufBP_O1yk"
      },
      "source": [
        "plt.scatter(X, y_outlier, s=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx07u9aLO1yo"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X, y_outlier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_5Oc3TO1ys"
      },
      "source": [
        "y_pred_outliers= lr.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsZ_jwBgO1yz"
      },
      "source": [
        "plt.scatter(X, y_outlier,s=5,label='actual')\n",
        "plt.scatter(X, y_pred_outliers,s=5,label='prediction with outliers')\n",
        "plt.scatter(X, y_pred,s=5,c='k', label='prediction sem outlier')\n",
        "plt.legend()\n",
        "plt.title('Linear Regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZJghaE-O1y4"
      },
      "source": [
        "lr.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMYaRMZxO1y8"
      },
      "source": [
        "ridge = Ridge(alpha = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8swmMWrWO1zA"
      },
      "source": [
        "ridge.fit(X, y_outlier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbrgmNIhO1zE"
      },
      "source": [
        "y_pred_ridge = ridge.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLEEbFHYO1zI"
      },
      "source": [
        "plt.scatter(X, y_outlier, s = 5,label = 'actual')\n",
        "plt.scatter(X, y_pred_outliers, s = 5, c = 'r' ,label = 'LinearRegression with outliers')\n",
        "plt.scatter(X, y_pred_ridge, s = 5, c = 'k', label = 'RidgeRegression with outlier')\n",
        "plt.legend()\n",
        "plt.title('Linear Regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL_0cZilO1zO"
      },
      "source": [
        "ridge.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q146_AyO1zS"
      },
      "source": [
        "## Efeito de $\\alpha$ na Regressão Ridge\n",
        "### Exemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydZvyvJ3O1zT"
      },
      "source": [
        "X, y, w = make_regression(n_samples = 10, \n",
        "                          n_features = 10, \n",
        "                          coef = True, \n",
        "                          random_state = 1, \n",
        "                          bias = 3.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z187ZGCqO1zY"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4UEPOD6O1zd"
      },
      "source": [
        "# Lasso\n",
        "* Reduz overfitting;\n",
        "* Se encarrega do Feature Selection, pois descarta variáveis altamente correlacionadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv4t9GlkO1ze"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha = .1)\n",
        "lasso.fit([[0, 0], [0, 0], [1, 1]],  [0, .1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLIbSdeSO1zj"
      },
      "source": [
        "lasso.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3AZohS2O1zq"
      },
      "source": [
        "Observe acima que o segundo coeficiente foi estimado como 0 e, desta forma, podemos excluí-lo do ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dazegSrTO1zr"
      },
      "source": [
        "# Elastic Net  \n",
        "* Combina o poder de Ridge e LASSO;\n",
        "* Remove variáveis de pouco poder preditivo (LASSO) ou as penaliza (Ridge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmfRQ4QKO1zs"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Instancia o objeto\n",
        "en = ElasticNet(alpha = .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwWarH8BO1zv"
      },
      "source": [
        "en.fit([[0, 0], [0, 0], [1, 1]],  [0, .1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2017DAXO1zz"
      },
      "source": [
        "en.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz2uKTAJO1z6"
      },
      "source": [
        "# Exemplo completo: Ridge\n",
        "* Adaptado de [Ridge and Lasso Regression: A Complete Guide with Python Scikit-Learn](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLUs3Y4lO1z7"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPVmVN83O1z_"
      },
      "source": [
        "boston = load_boston()\n",
        "df_Boston = pd.DataFrame(boston.data, columns = boston.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyf2IO9fO10D"
      },
      "source": [
        "X_boston = boston.data\n",
        "y_boston = boston.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mddJC9UyO10K"
      },
      "source": [
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_boston, y_boston, test_size = 0.2, random_state = 20111974)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GoluU_cO10S"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA603LoWO10W"
      },
      "source": [
        "# maior alpha --> mais restrição aos coeficientes; \n",
        "# Menor alpha --> mais generalização, e Ridge se assemelha da OLS\n",
        "rr = Ridge(alpha = 0.01)\n",
        "rr.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MvzKjBuO10a"
      },
      "source": [
        "# MSE\n",
        "rr_model=(mean_squared_error(y_true = y_treinamento, y_pred = rr.predict(X_treinamento)))\n",
        "print(rr_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjg0XJPWO10g"
      },
      "source": [
        "rr100 = Ridge(alpha=100)\n",
        "rr100.fit(X_treinamento, y_treinamento)\n",
        "train_score=lr.score(X_treinamento, y_treinamento)\n",
        "test_score=lr.score(X_teste, y_teste)\n",
        "Ridge_treinamento_score = rr.score(X_treinamento,y_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XpGG2_xO10j"
      },
      "source": [
        "# MSE\n",
        "rr100_model = (mean_squared_error(y_true = y_treinamento, y_pred = rr100.predict(X_treinamento)))\n",
        "print(rr100_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9YF1Jc0O10m"
      },
      "source": [
        "Ridge_teste_score = rr.score(X_teste, y_teste)\n",
        "Ridge_treinamento_score100 = rr100.score(X_treinamento, y_treinamento)\n",
        "Ridge_teste_score100 = rr100.score(X_teste, y_teste)\n",
        "print(\"linear regression train score:\", train_score)\n",
        "print(\"linear regression test score:\", test_score)\n",
        "print(\"ridge regression train score low alpha:\", Ridge_treinamento_score)\n",
        "print(\"ridge regression test score low alpha:\", Ridge_teste_score)\n",
        "print(\"ridge regression train score high alpha:\", Ridge_treinamento_score100)\n",
        "print(\"ridge regression test score high alpha:\", Ridge_teste_score100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHzgC53O10q"
      },
      "source": [
        "plt.plot(rr.coef_, \n",
        "         alpha = 0.7, \n",
        "         linestyle = 'none', \n",
        "         marker = '*', \n",
        "         markersize = 5, \n",
        "         color = 'red', \n",
        "         label = r'Ridge; \n",
        "         $\\alpha = 0.01$', \n",
        "         zorder = 7) # zorder for ordering the markers\n",
        "\n",
        "plt.plot(rr100.coef_,alpha = 0.5, \n",
        "         linestyle = 'none', \n",
        "         marker = 'd', \n",
        "         markersize = 6, \n",
        "         color = 'blue', \n",
        "         label = r'Ridge; \n",
        "         $\\alpha = 100$') # alpha here is for transparency\n",
        "\n",
        "plt.plot(lr.coef_, \n",
        "         alpha = 0.4, \n",
        "         linestyle = 'none', \n",
        "         marker = 'o', \n",
        "         markersize = 7, \n",
        "         color = 'green', \n",
        "         label = 'Linear Regression')\n",
        "\n",
        "plt.xlabel('Coefficient Index', fontsize = 16)\n",
        "plt.ylabel('Coefficient Magnitude',fontsize = 16)\n",
        "plt.legend(fontsize = 13, loc = 4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCwp0QRBO10u"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rr_model=(mean_squared_error(y_true= y, y_pred=regression.predict(X)))\n",
        "print(first_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPw-VP63O10x"
      },
      "source": [
        "# Exemplo completo - Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLu6v8HkO10y"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instancia o objeto:\n",
        "en = ElasticNet(normalize = True)\n",
        "\n",
        "# Otimização dos hiperparâmetros:\n",
        "d_hiperparametros = {'alpha': np.logspace(-5, 2, 8), \n",
        "                     'l1_ratio': [.2, .4, .6, .8]}\n",
        "\n",
        "search = GridSearchCV(estimator = en, \n",
        "                      param_grid = d_hiperparametros, \n",
        "                      scoring = 'neg_mean_squared_error', \n",
        "                      n_jobs = 1,\n",
        "                      refit = True, \n",
        "                      cv = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzirI7FJO101"
      },
      "source": [
        "search.fit(X, y)\n",
        "search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqPPkVP5O105"
      },
      "source": [
        "en2 = ElasticNet(normalize = True, alpha = 0.001, l1_ratio = 0.6)\n",
        "en2.fit(X, y)\n",
        "\n",
        "ml2 = (mean_squared_error(y_true = y, y_pred = en2.predict(X)))\n",
        "print(ml2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH_iEuzhO109"
      },
      "source": [
        "# Exercício 1 - Mall_Customers.csv\n",
        "> A variável-target deste dataframe é 'Annual Income'. Desenvolva um modelo de regressão utilizando OLS, Ridge e LASSO e compare os resultados.\n",
        "\n",
        "* Experimente:\n",
        "    * Lasso(alpha = 0.01, max_iter = 10e5);\n",
        "    * Lasso(alpha = 0.0001, max_iter = 10e5);\n",
        "    * Ridge(alpha = 0.01);\n",
        "    * Ridge(alpha = 100);"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfRDEaaRYxFQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt \n",
        "plt.rc(\"font\", size=14)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nulrLzUqYxFY"
      },
      "source": [
        "## Data\n",
        "\n",
        "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe (1/0) a term deposit (variable y)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LdrQCwxYxFY"
      },
      "source": [
        "This dataset provides the customer information. It includes 41188 records and 21 fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoT6zkoFYxFZ"
      },
      "source": [
        "df_bank = pd.read_csv('https://raw.githubusercontent.com/MathMachado/DataFrames/master/bank-full.csv', header = 0)\n",
        "df_bank = df_bank.dropna()\n",
        "print(df_bank.shape)\n",
        "print(list(df_bank.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD23hMCeYxFc"
      },
      "source": [
        "df_bank.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtGbim_EYxFh"
      },
      "source": [
        "#### Input variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pJ7ai5ZYxFh"
      },
      "source": [
        "1 - age (numeric)\n",
        "\n",
        "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "\n",
        "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "\n",
        "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "\n",
        "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
        "\n",
        "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
        "\n",
        "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
        "\n",
        "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
        "\n",
        "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "\n",
        "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "\n",
        "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "\n",
        "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "\n",
        "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "\n",
        "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
        "\n",
        "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "\n",
        "16 - emp.var.rate: employment variation rate - (numeric)\n",
        "\n",
        "17 - cons.price.idx: consumer price index - (numeric)\n",
        "\n",
        "18 - cons.conf.idx: consumer confidence index - (numeric) \n",
        "\n",
        "19 - euribor3m: euribor 3 month rate - (numeric)\n",
        "\n",
        "20 - nr.employed: number of employees - (numeric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwsaBV_OYxFi"
      },
      "source": [
        "#### Predict variable (desired target):\n",
        "\n",
        "y - has the client subscribed a term deposit? (binary: '1','0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SsNWV_SYxFj"
      },
      "source": [
        "The education column of the dataset has many categories and we need to reduce the categories for a better modelling. The education column has the following categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TFbgh3vYxFk"
      },
      "source": [
        "df_bank['education'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luv7Bdf_YxFn"
      },
      "source": [
        "Let us group \"basic.4y\", \"basic.9y\" and \"basic.6y\" together and call them \"basic\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkOlUOs2YxFn"
      },
      "source": [
        "df_bank['education']=np.where(df_bank['education'] =='basic.9y', 'Basic', df_bank['education'])\n",
        "df_bank['education']=np.where(df_bank['education'] =='basic.6y', 'Basic', df_bank['education'])\n",
        "df_bank['education']=np.where(df_bank['education'] =='basic.4y', 'Basic', df_bank['education'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-X1WMv2YxFq"
      },
      "source": [
        "After grouping, this is the columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9LlgpkjYxFq"
      },
      "source": [
        "df_bank['education'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcnJy3KYYxFt"
      },
      "source": [
        "### Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUrTMR8BYxFt"
      },
      "source": [
        "df_bank['y'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpzHnzJKYxFx"
      },
      "source": [
        "sns.countplot(x='y',data=df_bank, palette='hls')\n",
        "plt.show()\n",
        "plt.savefig('count_plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C99nOe3mYxF0"
      },
      "source": [
        "There are 36548 no's and 4640 yes's in the outcome variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nGaox_kYxF1"
      },
      "source": [
        "Let's get a sense of the numbers across the two classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQvzA60bYxF1"
      },
      "source": [
        "df_bank.groupby('y').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3xjoceKYxF3"
      },
      "source": [
        "Observations:\n",
        "\n",
        "The average age of customers who bought the term deposit is higher than that of the customers who didn't.\n",
        "The pdays (days since the customer was last contacted) is understandably lower for the customers who bought it. The lower the pdays, the better the memory of the last call and hence the better chances of a sale.\n",
        "Surprisingly, campaigns (number of contacts or calls made during the current campaign) are lower for customers who bought the term deposit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvzGMePPYxF4"
      },
      "source": [
        "We can calculate categorical means for other categorical variables such as education and marital status to get a more detailed sense of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqLVMjoxYxF5"
      },
      "source": [
        "df_bank.groupby('job').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTUeRJAtYxF7"
      },
      "source": [
        "df_bank.groupby('marital').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsxdFumiYxF9"
      },
      "source": [
        "df_bank.groupby('education').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i1DCWV-YxGA"
      },
      "source": [
        "Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEArHQPbYxGB"
      },
      "source": [
        "%matplotlib inline\n",
        "pd.crosstab(df_bank.job,df_bank.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Job Title')\n",
        "plt.xlabel('Job')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('purchase_fre_job')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNwo5du_YxGD"
      },
      "source": [
        "The frequency of purchase of the deposit depends a great deal on the job title. Thus, the job title can be a good predictor of the outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM7CWfAZYxGE"
      },
      "source": [
        "table=pd.crosstab(df_bank.marital,df_bank.y)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
        "plt.title('Stacked Bar Chart of Marital Status vs Purchase')\n",
        "plt.xlabel('Marital Status')\n",
        "plt.ylabel('Proportion of Customers')\n",
        "plt.savefig('mariral_vs_pur_stack')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWBLh7toYxGG"
      },
      "source": [
        "Hard to see, but the marital status does not seem a strong predictor for the outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh_u4QphYxGH"
      },
      "source": [
        "table=pd.crosstab(df_bank.education,df_bank.y)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
        "plt.title('Stacked Bar Chart of Education vs Purchase')\n",
        "plt.xlabel('Education')\n",
        "plt.ylabel('Proportion of Customers')\n",
        "plt.savefig('edu_vs_pur_stack')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9AgJroYYxGK"
      },
      "source": [
        "Education seems a good predictor of the outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHI2LT-IYxGL"
      },
      "source": [
        "pd.crosstab(df_bank.day_of_week,df_bank.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('pur_dayofweek_bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A2jmS4MYxGR"
      },
      "source": [
        "Day of week may not be a good predictor of the outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzafDBHpYxGS"
      },
      "source": [
        "pd.crosstab(df_bank.month,df_bank.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('pur_fre_month_bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CBtquEYxGW"
      },
      "source": [
        "Month might be a good predictor of the outcome variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgF_3SqWYxGY"
      },
      "source": [
        "df_bank.age.hist()\n",
        "plt.title('Histogram of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('hist_age')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0FhKYDsYxGc"
      },
      "source": [
        "The most of the customers of the bank in this dataset are in the age range of 30-40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nd3yV7DYxGd"
      },
      "source": [
        "pd.crosstab(df_bank.poutcome,df_bank.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Poutcome')\n",
        "plt.xlabel('Poutcome')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('pur_fre_pout_bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRKUAGrjYxGh"
      },
      "source": [
        "Poutcome seems to be a good predictor of the outcome variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63RLRI9uYxGi"
      },
      "source": [
        "### Create dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8S4WUKmYxGj"
      },
      "source": [
        "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
        "for var in cat_vars:\n",
        "    cat_list='var'+'_'+var\n",
        "    cat_list = pd.get_dummies(df_bank[var], prefix=var)\n",
        "    df_bank1=df_bank.join(cat_list)\n",
        "    data=df_bank1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX3w9i9WYxGl"
      },
      "source": [
        "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
        "df_bank_vars=df_bank.columns.values.tolist()\n",
        "to_keep=[i for i in df_bank_vars if i not in cat_vars]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMX_82xaYxGq"
      },
      "source": [
        "df_bank_final=df_bank[to_keep]\n",
        "df_bank_final.columns.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkTjpxYoYxGr"
      },
      "source": [
        "df_bank_final_vars=df_bank_final.columns.values.tolist()\n",
        "y=['y']\n",
        "X=[i for i in df_bank_final_vars if i not in y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QbKaRcsYxGt"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkxjW1AQYxGu"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "rfe = RFE(logreg, 18)\n",
        "rfe = rfe.fit(df_bank_final[X], df_bank_final[y] )\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P9hd4jHYxGw"
      },
      "source": [
        "The Recursive Feature Elimination (RFE) has helped us select the following features: \"previous\", \"euribor3m\", \"job_blue-collar\", \"job_retired\", \"job_services\", \"job_student\", \"default_no\", \"month_aug\", \"month_dec\", \"month_jul\", \"month_nov\", \"month_oct\", \"month_sep\", \"day_of_week_fri\", \"day_of_week_wed\", \"poutcome_failure\", \"poutcome_nonexistent\", \"poutcome_success\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PW8WZX_YxGx"
      },
      "source": [
        "cols=[\"previous\", \"euribor3m\", \"job_blue-collar\", \"job_retired\", \"job_services\", \"job_student\", \"default_no\", \n",
        "      \"month_aug\", \"month_dec\", \"month_jul\", \"month_nov\", \"month_oct\", \"month_sep\", \"day_of_week_fri\", \"day_of_week_wed\", \n",
        "      \"poutcome_failure\", \"poutcome_nonexistent\", \"poutcome_success\"] \n",
        "X=df_bank_final[cols]\n",
        "y=df_bank_final['y']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix0mN9qxYxG0"
      },
      "source": [
        "### Implementing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbx2bwtiYxG0"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "logit_model=sm.Logit(y,X)\n",
        "result=logit_model.fit()\n",
        "print(result.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR1ui-UcYxG2"
      },
      "source": [
        "The p-values for most of the variables are very small, therefore, most of them are significant to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GHhrsaeYxG3"
      },
      "source": [
        "### Logistic Regression Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFQnH5MzYxG3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUa3QL7tYxG6"
      },
      "source": [
        "#### Predicting the test set results and caculating the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD-y2e33YxG6"
      },
      "source": [
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkPWzos7YxG-"
      },
      "source": [
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwC3rt_6YxHA"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muw50oqSYxHB"
      },
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "modelCV = LogisticRegression()\n",
        "scoring = 'accuracy'\n",
        "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y8XCTqoYxHE"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCza9NkVYxHE"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9SapwS2YxHG"
      },
      "source": [
        "The result is telling us that we have 10872+254 correct predictions and 1122+109 incorrect predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bEWvWScYxHG"
      },
      "source": [
        "#### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaH2nESwYxHH"
      },
      "source": [
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6oxlhbpYxHJ"
      },
      "source": [
        "#### Compute precision, recall, F-measure and support\n",
        "\n",
        "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "\n",
        "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
        "\n",
        "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
        "\n",
        "The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n",
        "\n",
        "The support is the number of occurrences of each class in y_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhN5_p4yYxHK"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzSFVEnAYxHP"
      },
      "source": [
        "#### Interpretation: \n",
        "\n",
        "Of the entire test set, 88% of the promoted term deposit were the term deposit that the customers liked. Of the entire test set, 90% of the customer's preferred term deposit were promoted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGXJ6g2nYxHQ"
      },
      "source": [
        "### ROC Curvefrom sklearn import metrics\n",
        "from ggplot import *\n",
        "\n",
        "prob = clf1.predict_proba(X_test)[:,1]\n",
        "fpr, sensitivity, _ = metrics.roc_curve(Y_test, prob)\n",
        "\n",
        "df = pd.DataFrame(dict(fpr=fpr, sensitivity=sensitivity))\n",
        "ggplot(df, aes(x='fpr', y='sensitivity')) +\\\n",
        "    geom_line() +\\\n",
        "    geom_abline(linetype='dashed')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9QKDuS0YxHQ"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUOjbQ-zPHz_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DimhsE9bPTjM"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "df_boston = pd.DataFrame(load_boston().data, columns = load_boston().feature_names)\n",
        "df_boston['preco'] = load_boston().target\n",
        "df_boston.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7dhV0eTPbVN"
      },
      "source": [
        "df_boston.columns = [col.lower() for col in df_boston.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N83q42Y5advX"
      },
      "source": [
        "df_boston.plot(kind = 'kde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCyfcQKwPwp6"
      },
      "source": [
        "for col in df_boston:\n",
        "  f_media = df_boston [col].mean()\n",
        "  f_desvio = df_boston [col].std()\n",
        "  f_limite_superior = f_media + 2.5 * f_desvio\n",
        "  f_limite_inferior = f_media - 2.5 * f_desvio\n",
        "  df_boston.loc [df_boston [col] > f_limite_superior, col] = f_limite_superior\n",
        "  df_boston.loc [df_boston [col] < f_limite_inferior, col] = f_limite_inferior\n",
        "df_boston.head (10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQwYdjwQtLF"
      },
      "source": [
        "df_boston.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFdSsWqeZoaJ"
      },
      "source": [
        "df_boston.plot(kind = 'kde', figsize = (32, 12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvsD6P4sa73v"
      },
      "source": [
        "df_boston_MinMaxScaler = MinMaxScaler().fit_transform(df_boston)\n",
        "df_boston_MinMaxScaler = pd.DataFrame(df_boston_MinMaxScaler, columns = df_boston.columns)\n",
        "df_boston_MinMaxScaler.plot(kind = 'kde', figsize = (32, 12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ4Zj5JfdNg4"
      },
      "source": [
        "X_boston = df_boston.drop(columns = ['preco'], axis = 1)\n",
        "y_boston = df_boston['preco']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW2LG0C4dUxu"
      },
      "source": [
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_boston, y_boston, test_size = 0.2, random_state = 20111974)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUE661VZb99n"
      },
      "source": [
        "X2_treinamento = sm.add_constant(X_treinamento)\n",
        "lm_sm = sm.OLS(y_treinamento, X2_treinamento).fit()\n",
        "print(lm_sm.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t5aXhVSdmFK"
      },
      "source": [
        "X2 = X_treinamento.drop(columns = 'age')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKJSR0hbdk5O"
      },
      "source": [
        "X3_treinamento = sm.add_constant(X2)\n",
        "lm2_sm = sm.OLS(y_treinamento, X3_treinamento).fit()\n",
        "print(lm2_sm.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9NyE0QmeRP3"
      },
      "source": [
        "X3 = X2.drop(columns = 'indus')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE-I155feb8G"
      },
      "source": [
        "X4_treinamento = sm.add_constant(X3)\n",
        "lm3_sm = sm.OLS(y_treinamento, X4_treinamento).fit()\n",
        "print(lm3_sm.summary())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}